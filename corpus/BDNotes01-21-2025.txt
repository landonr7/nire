BDNotes 01-21-2025: 
Example (MapReduce): Language Model
    - Statistical machine translation
        - Need to count number of timers every 5-word sequence occurs
         in a large corpus of documents

Additions to python code for HM0 (put before last line of code)
if os.path.exists(output_dir):
    shutil.rmtree(output_dir)

HW0 Steps
    -reserve space on cluster with: "spark-node4me.sh"
    - load spark module 2.3.0 with "module load spark/2.3.0"
    - naviagte to HW0 directory
    - "spark-submit pywordcount.py (i didnt see the rest but i think 
    it is on instructions)"
    - upload the output text file with key value pairs

MapReduce: Environment
    - Takes care of partitioning input data
    - Takes care of scheduling program execution across machines
    - Performs group by key step
    - Handles machine failure
    - Managing required inter-machine communication

Coordination: Master
    - Master node takes care of:
        - task status: idle, in-process, completed
        - When map task completes, is sends master location and sizes 
        of its R intermediate files
        - Master pushes work to reducers

Dealing with Failures
    - Map worker failure
        - Map tasks completed or in-progress are set to idle
        - Reduce workers are notiffied when task is rescheduled on 
        another worker
    - Reduce worker failure
        - Only in-progress tasks are set to idle
        - Task is restarted
    - Master failure
        - MapReduce task is aborted and client is notified

How Many MapReduce Tasks Needed?
    - M map tasks, R reduce tasks
    - Rule of Thumb: "Make M much larger than the number of nodes in 
    the cluster" 
    - Improves dynamic load balancing and speeds up recovery from 
    worker failures
    - Usually R is smaller than M
        - Because output is spread across R files

Refinement: Combiners
    - Network time can be saved by pre-aggregating values in the 
    mapper
        - combine(k, list(v1)) -> v2
        - Combiner is usually same
        as the reduce function
    - Works only if reduce function is communative and associative
        - Sum, Average
        - Median is NOT communative OR associative

Refinement: Partition Function
    - Want to control how keys get partitioned
    - System uses a default partition function
    - Sometimes useful to override the hash function

Implementations
    - Google
    - Hadoop
    - Spark

Cloud Computing
    - Renting computing by the hour
    - Amazon's "Elastic Compute Cloud" (EC2)
        - S3
        - Elastic MapReduce (EMR)

How to Design MapReduce Programs
    - What data are distributed?
    - What computations are included in the program?
        - What computations can be conducted locally (so they can be 
        put in map)?
        - What computations cannot be conducted locally (so they 
        should be put in reduce)?
        - How do we aggregate computations (can be used to determine 
        the key for intermediate key-value pairs)?

Matrix-Vector Multiplication by MapReduce
    - M is an n x n matrix
    - v is a vector of length n
    - Compute M x v where: x_i = sigma_j=1->n(m_i,j * v_j)
    - M cannot fit in main memory
    - Assume v fits in main memory
    - Read m_i,j and v into main memory
    - Map function:
        - For each element m_i,j, a mapper preducers a key-value 
        pair (i, m_i,j * v_j)
    - Group: 
        - Each reducer recieves 
        (i, <m_i,1 * v_1, m_i,2 * v_2, ..., m_i,n * v_n>)
    - Reduce function:
        - Sum all values and output 